{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4f6855-14a4-40c1-9c57-7236fe577a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7908e539-b772-4fe0-a67f-94e4f0b46643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import heapq\n",
    "\n",
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = defaultdict(TrieNode)\n",
    "        self.is_end_of_word = False\n",
    "        self.frequency =0\n",
    "        self.word =None\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root =TrieNode()\n",
    "\n",
    "    def insert(self, word, frequency =1):\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            node =  node.children[char]\n",
    "        node.is_end_of_word =True\n",
    "        node.frequency +=frequency\n",
    "        node.word =word\n",
    "\n",
    "    def autocomplete(self, prefix, top_n =3):\n",
    "        node =self.root\n",
    "        for char in prefix:\n",
    "            if char not in node.children:\n",
    "                return []\n",
    "            node = node.children[char]\n",
    "\n",
    "\n",
    "        result_heap = []\n",
    "\n",
    "        def dfs(current_node):\n",
    "            if current_node.is_end_of_word:\n",
    "                heapq.heappush(result_heap, (-current_node.frequency, current_node.word))\n",
    "            for child in current_node.children.values():\n",
    "                dfs(child)\n",
    "\n",
    "\n",
    "        dfs(node)\n",
    "\n",
    "        top_suggestions =[]\n",
    "        for _ in range(min(top_n, len(result_heap))):\n",
    "            freq, word = heapq.heappop(result_heap)\n",
    "            top_suggestions.append((word, -freq))\n",
    "    \n",
    "        return top_suggestions\n",
    "\n",
    "\n",
    "    def increase_frequency(self, word, amount =1): #for auto-learning frequency\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node.children:\n",
    "                print(f\"Word {word} not found in Trie\")\n",
    "                return False\n",
    "            node = node.children[char]\n",
    "\n",
    "        if node.is_end_of_word:\n",
    "            node.frequency+= amount\n",
    "            print(f\"Frequency of {word} updated to {node.frequency}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"{word} is not a complete word in Trie.\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc11f384-e3d1-41ce-9e49-7a34ae2189ee",
   "metadata": {},
   "source": [
    "### 1. Levenshtein Eidt Distance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bf405f63-34ea-4afd-b3fe-59a1a39f0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(word1, word2):\n",
    "    m, n =len(word1), len(word2)\n",
    "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "\n",
    "    for i in range(m+1):\n",
    "        dp[i][0] =i\n",
    "    for j in range(n+1):\n",
    "        dp[0][j] =j\n",
    "\n",
    "    for i in range(1, m+1):\n",
    "        for j in range(1, n+1):\n",
    "            if word1[i-1] == word2[j-1]:\n",
    "                dp[i][j] =dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] =1+ min(dp[i-1][j], #delete\n",
    "                                 dp[i][j-1], #insert\n",
    "                                 dp[i-1][j-1])  #replace\n",
    "\n",
    "    return dp[m][n]\n",
    "\n",
    "\n",
    "####### for Spelling Corrector using Levenshtein\n",
    "def correct_prefix(trie, typo_prefix, max_distance =2):\n",
    "    candidates = []\n",
    "    all_words = collect_all_words(trie.root)\n",
    "\n",
    "    for word,freq in all_words:\n",
    "        if len(word) >= len(typo_prefix):\n",
    "            w_prefix =word[:len(typo_prefix)]\n",
    "            distance = edit_distance(typo_prefix, w_prefix)\n",
    "            if distance <= max_distance:\n",
    "                candidates.append((distance, -freq, w_prefix))\n",
    "\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "\n",
    "    # Sort by lowes distance, highest frequency\n",
    "    candidates.sort\n",
    "    return candidates[0][2] #return corrected prefix\n",
    "\n",
    "\n",
    "def smart_autocomplete(trie, raw_prefix, top_n=5):\n",
    "    #Try exact match first\n",
    "    results = trie.autocomplete(raw_prefix, top_n)\n",
    "    if results:\n",
    "        return results\n",
    "\n",
    "    #Otherwise correct the prefix\n",
    "    corrected =correct_prefix(trie, raw_prefix)\n",
    "    if corrected:\n",
    "        print(f\"Prefix {raw_prefix} corrected to {corrected}\")\n",
    "        return trie.autocomplete(corrected, top_n)\n",
    "    else:\n",
    "        print(f\"No correction found for {raw_prefix}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9027f9a2-e958-445d-9b27-00ff4738d147",
   "metadata": {},
   "source": [
    "### 2. Helper to Collect All Words from Trie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4515837b-b05b-4325-b048-a5570a3e7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helper to the notebook to get all valid words + frequencies form the Trie:\n",
    "\n",
    "\n",
    "def collect_all_words(node, words =None):\n",
    "    if words is None:\n",
    "        words =[]\n",
    "\n",
    "    if node.is_end_of_word:\n",
    "        words.append((node.word , node.frequency))\n",
    "\n",
    "\n",
    "    for child in node.children.values():  # âœ… correct method\n",
    "        collect_all_words(child, words)\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3130c5c-1745-4692-b785-a0c2beaf6cc3",
   "metadata": {},
   "source": [
    "### 3. Fuzzy Autocomplete Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b6745c1d-8604-4df6-9b2e-a11a8f1b9703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_autocomplete(trie, typo_prefix, max_distance =1 , top_n=5):\n",
    "    all_words = collect_all_words(trie.root)\n",
    "    close_matches = []\n",
    "\n",
    "    for word, freq in all_words:\n",
    "        prefix_part =word[:len(typo_prefix)]\n",
    "        if edit_distance(typo_prefix, prefix_part) <= max_distance:\n",
    "            close_matches.append((word, freq))\n",
    "\n",
    "    top_results = sorted(close_matches, key = lambda x: -x[1])[:top_n]\n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "35e3dfd6-8ef3-49b2-a63e-2aff7490db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trie = Trie()\n",
    "trie.insert(\"help\", 8)\n",
    "trie.insert(\"helper\", 5)\n",
    "trie.insert(\"helping\", 3)\n",
    "trie.insert(\"held\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "79e481d1-e8f9-458f-b102-2be855520840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of help updated to 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate user selecting a word\n",
    "selected_word = \"help\"\n",
    "trie.increase_frequency(selected_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6ce0e13c-e43c-4749-8b66-ef9704574fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('help', 9), ('helper', 5), ('held', 4)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trie.autocomplete(\"hel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7f45715d-df91-488a-a6f4-f307881979d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prefix hte corrected to the\n",
      "[('there', 7), ('theory', 5), ('theme', 3)]\n"
     ]
    }
   ],
   "source": [
    "trie = Trie()\n",
    "trie.insert(\"theory\", 5)\n",
    "trie.insert(\"there\", 7)\n",
    "trie.insert(\"theme\", 3)\n",
    "\n",
    "print(smart_autocomplete(trie, \"hte\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ad9bf031-d7f5-4618-a61d-c6355e5f5849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(fuzzy_autocomplete(trie, \"hepl\"))  # Typo of 'help'\n",
    "print(fuzzy_autocomplete(trie, \"hel\", max_distance=0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2cb49b-2b08-4deb-8e13-e08b881d7d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
